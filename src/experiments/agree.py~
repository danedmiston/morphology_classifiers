import pandas as pd
import numpy as np
from utils.loader import *
from utils.book_keeping import *
from conll.lexicon import Lexicon
from utils.viz import *
from utils.attention import *
import pickle

class Agree():
    def __init__(self, language, feature):
        self.language = language
        self.feature = feature


        self.lexicon = Lexicon(self.language)
        self.attentions = load_attentions(self.language, self.feature)


    def score_distribution(self, ids, distribution, in_agree):
        """
        Scores a single distribution; helper function to evaluat_distributions
        Compares how much attention on agree set relative to how much is 
        expected at random

        args:
        ids: (int) --- tuple of ints; locations of words in agree relation
        distribution: np.array --- array of size (len(sentence.split()), 1), 
        one row in a heatmap
        in_agree: bool --- if True, then random_expectation should be len(ids)-1, 
        otherwise, should be len(ids)
        """
        if in_agree:
            random_expectation = (len(ids)-1)/(len(distribution)-1)
            agree_score = distribution[[prob for prob in ids]].sum() / random_expectation
        else:
            random_expectation = len(ids)/(len(distribution)-1)
            agree_score = distribution[[prob for prob in ids]].sum() / random_expectation
        return(agree_score)
        
        
    def evaluate_heatmap(self, ids, heatmap):
        # Scores an entire heatmap
        attentions = renormalize_attention(heatmap) # Sets heatmap[i,i]=0 and renormalizes
        agree_scores = []
        out_scores = []
        agree_set = attentions[[dist for dist in ids]]
        out_set = attentions[[dist for dist in range(len(attentions)) if dist not in ids]]
        for row in agree_set:
            agree_scores.append(self.score_distribution(ids, row, in_agree=True))
        for row in out_set:
            out_scores.append(self.score_distribution(ids, row, in_agree=False))
        agree_avg = np.mean(agree_scores)
        out_avg = np.mean(out_scores)
        return(agree_avg/out_avg)


    
    def evaluate_heatmap_random(self, ids, heatmap):
        # Creates normalized random heatmap of same size as heatmap 
        attentions = renormalize_attention(np.random.random_sample([len(heatmap), len(heatmap)]))
        agree_scores = []
        out_scores = []
        agree_set = attentions[[dist for dist in ids]]
        out_set = attentions[[dist for dist in range(len(attentions)) if dist not in ids]]
        for row in agree_set:
            agree_scores.append(self.score_distribution(ids, row, in_agree=True))
        for row in out_set:
            out_scores.append(self.score_distribution(ids, row, in_agree=False))
        agree_avg = np.mean(agree_scores)
        out_avg = np.mean(out_scores)
        return(agree_avg/out_avg)
    
    def evaluate_head(self, head):
        scores = []
        for layer in range(12):
            for _, row in self.attentions[layer].iterrows():
                agree = row["Agree"]
                ids = row["IDs"]
                heatmap = row["Attentions"][head]
                score = self.evaluate_heatmap(ids, heatmap)
                scores.append(score)
        avg_score = np.mean(scores)
        return(avg_score)

    def evaluate_random(self, head):
        # Sets a random baseline. Suitable for head or layer
        scores_random = []
        for layer in range(12):
            for _, row in self.attentions[layer].iterrows():
                agree = row["Agree"]
                ids = row["IDs"]
                heatmap = row["Attentions"][head]
                score = self.evaluate_heatmap_random(ids, heatmap)
                scores_random.append(score)
        avg_score = np.mean(scores_random)
        return(avg_score)

    def evaluate_layer(self, layer):
        scores = []
        for head in range(12):
            for _, row in self.attentions[layer].iterrows():
                agree = row["Agree"]
                ids = row["IDs"]
                heatmap = row["Attentions"][head]
                score = self.evaluate_heatmap(ids, heatmap)
                scores.append(score)
        avg_score = np.mean(scores)
        return(avg_score)

    def run_agree_experiment(self, output=True):
        scores = np.empty((12,12))
        for layer in range(12):
            print("Processing layer", layer+1)
            for head in range(12):
                temp_scores = []
                for _, row in self.attentions[layer].iterrows():
                    ids = row["IDs"]
                    heatmap = row["Attentions"][head]
                    score = self.evaluate_heatmap(ids,heatmap)
                    temp_scores.append(score)
                scores[layer, head] = np.mean(temp_scores)
        scores = pd.DataFrame(scores, index=["Layer="+str(i) for i in range(1,13)],
                              columns=["Head="+str(i) for i in range(1,13)])
        if output:
            pickle.dump(scores, open(Agree_Results[self.language] + self.feature + ".p", "wb"))
        viz_layers_heads(scores.values)
        return(scores)
                              
                
    def run_agree_experiment_head(self, output=True):
        if output:
            with open(Agree_Results[self.language] + self.feature + "_head.txt", "w") as fout:
                for head in range(12):
                    avg_score = self.evaluate_head(head)
                    print("Avg. score for head", head+1, ":", avg_score)
                    fout.write("Avg. score for head="+str(head+1)+": "+str(avg_score)+"\n\n")
                avg_random = self.evaluate_random(head)
                print("Avg. score on random heatmaps:", avg_random)
                fout.write("Avg. score on random heatmaps: "+str(avg_random)+"\n\n")
        else:
            for head in range(12):
                avg_score = self.evaluate_head(head)
                print("Avg. score for head", head+1, ":", avg_score)
            avg_random = self.evaluate_random(head)
            print("Avg. score on random heatmaps:", avg_random)


    def run_agree_experiment_layer(self, output=True):
        if output:
            with open(Agree_Results[self.language] + self.feature + "_layer.txt", "w") as fout:
                for layer in range(12):
                    avg_score = self.evaluate_layer(layer)
                    print("Avg. score for layer", layer+1, ":", avg_score)
                    fout.write("Avg. score for layer="+str(layer+1)+": "+str(avg_score)+"\n\n")
                avg_random = self.evaluate_random(0)
                print("Avg. score on random heatmaps:", avg_random)
                fout.write("Avg. score on random heatmaps: "+str(avg_random)+"\n\n")
        else:
            for layer in range(12):
                avg_score = self.evaluate_layer(layer)
                print("Avg. score for head", layer+1, ":", avg_score)
            avg_random = self.evaluate_random(0)
            print("Avg. score on random heatmaps:", avg_random)

                
